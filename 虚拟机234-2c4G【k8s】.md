```bash
# 192.168.10 one.kube.huang
# 192.168.11 two.kube.huang
# 192.168.12 three.kube.huang
```

## 01 修改hosts

```bash
# 类似与下面的这个
cat /etc/hosts
cat >> /etc/hosts <<- _EOF_
127.0.0.1 apiserver.k8s.local
192.168.10 one.kube.huang
192.168.11 two.kube.huang
192.168.12 three.kube.huang
_EOF_
cat /etc/hosts
```

## 02 离线升级内核

```bash
# 或者本地安装
yum -y install ./kernel-lt-5.4.220-1.el7.elrepo.x86_64.rpm
yum -y install ./kernel-lt-devel-5.4.220-1.el7.elrepo.x86_64.rpm
```

## 03 更换启动项

```bash
# 查看系统上的所有可用内核
awk -F\' '$1=="menuentry " {print i++ " : " $2}' /etc/grub2.cfg
# 设置新的内核为grub2的默认版本
grub2-set-default 'CentOS Linux (5.4.220-1.el7.elrepo.x86_64) 7 (Core)'
# 生成 grub 配置文件并重启
grub2-editenv list
grub2-mkconfig -o /boot/grub2/grub.cfg
reboot 
```

## 04 安装基础环境

```bash
yum update -y
yum -y install epel-release gcc bc gcc-c++ ncurses ncurses-devel cmake elfutils-libelf-devel openssl-devel flex* bison* autoconf automake zlib* fiex* libxml* ncurses-devel libmcrypt* libtool-ltdl-devel* make cmake  pcre pcre-devel openssl openssl-devel jemalloc-devel tlc libtool vim unzip wget lrzsz bash-comp* ipvsadm ipset jq sysstat conntrack libseccomp conntrack-tools socat curl wget git conntrack-tools psmisc nfs-utils tree bash-completion conntrack libseccomp net-tools crontabs sysstat iftop nload strace bind-utils tcpdump htop telnet lsof 
```

## 05 关闭防火墙和swap,selinux

```bash
#关闭防火墙
systemctl disable --now firewalld NetworkManager
#关闭swap
swapoff -a
sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab
# 或者 sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
#关闭selinux
setenforce 0
# sed -e '/^[^#]*SELINUX=/p' /etc/selinux/config
sed -ri '/^[^#]*SELINUX=/s#=.+$#=disabled#' /etc/selinux/config
```

## 06 加载ipvs

内核4.19及4.19以上的用这个ipvs配置文件

```bash
:> /etc/modules-load.d/ipvs.conf
module=(
ip_vs
ip_vs_rr
ip_vs_wrr
ip_vs_sh
nf_conntrack
br_netfilter
  )
for kernel_module in ${module[@]};do
    /sbin/modinfo -F filename $kernel_module |& grep -qv ERROR && echo $kernel_module >> /etc/modules-load.d/ipvs.conf || :
done
```

内核4.19以下的，不包括4.19，用这个ipvs配置文件

```bash
:> /etc/modules-load.d/ipvs.conf
module=(
ip_vs
ip_vs_rr
ip_vs_wrr
ip_vs_sh
nf_conntrack_ipv4
br_netfilter
  )
for kernel_module in ${module[@]};do
    /sbin/modinfo -F filename $kernel_module |& grep -qv ERROR && echo $kernel_module >> /etc/modules-load.d/ipvs.conf || :
done
```

加载ipvs模块

```bash
systemctl daemon-reload
systemctl enable --now systemd-modules-load.service
# 验证
lsmod | grep ip_vs
lsmod | grep -e ip_vs -e nf_conntrack
```

## 07 设置k8s系统参数

```bash
cat <<EOF > /etc/sysctl.d/k8s.conf
net.ipv6.conf.all.disable_ipv6 = 1           #禁用ipv6
net.ipv6.conf.default.disable_ipv6 = 1       #禁用ipv6
net.ipv6.conf.lo.disable_ipv6 = 1            #禁用ipv6
net.ipv4.neigh.default.gc_stale_time = 120   #决定检查过期多久邻居条目
net.ipv4.conf.all.rp_filter = 0              #关闭反向路由校验
net.ipv4.conf.default.rp_filter = 0          #关闭反向路由校验
net.ipv4.conf.default.arp_announce = 2       #始终使用与目标IP地址对应的最佳本地IP地址作为ARP请求的源IP地址
net.ipv4.conf.lo.arp_announce = 2            #始终使用与目标IP地址对应的最佳本地IP地址作为ARP请求的源IP地址
net.ipv4.conf.all.arp_announce = 2           #始终使用与目标IP地址对应的最佳本地IP地址作为ARP请求的源IP地址
net.ipv4.ip_forward = 1                      #启用ip转发功能
net.ipv4.tcp_max_tw_buckets = 5000           #表示系统同时保持TIME_WAIT套接字的最大数量
net.ipv4.tcp_syncookies = 1                  #表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理
net.ipv4.tcp_max_syn_backlog = 1024          #接受SYN同包的最大客户端数量
net.ipv4.tcp_synack_retries = 2              #活动TCP连接重传次数
net.bridge.bridge-nf-call-ip6tables = 1      #要求iptables对bridge的数据进行处理
net.bridge.bridge-nf-call-iptables = 1       #要求iptables对bridge的数据进行处理
net.bridge.bridge-nf-call-arptables = 1      #要求iptables对bridge的数据进行处理
net.netfilter.nf_conntrack_max = 2310720     #修改最大连接数
fs.inotify.max_user_watches=89100            #同一用户同时可以添加的watch数目
fs.may_detach_mounts = 1                     #允许文件卸载
fs.file-max = 52706963                       #系统级别的能够打开的文件句柄的数量
fs.nr_open = 52706963                        #单个进程可分配的最大文件数
vm.overcommit_memory=1                       #表示内核允许分配所有的物理内存，而不管当前的内存状态如何
vm.panic_on_oom=0                            #内核将检查是否有足够的可用内存供应用进程使用
vm.swappiness = 0                            #关注swap
net.ipv4.tcp_keepalive_time = 600            #修复ipvs模式下长连接timeout问题,小于900即可
net.ipv4.tcp_keepalive_intvl = 30            #探测没有确认时，重新发送探测的频度
net.ipv4.tcp_keepalive_probes = 10           #在认定连接失效之前，发送多少个TCP的keepalive探测包
vm.max_map_count=262144                      #定义了一个进程能拥有的最多的内存区域
EOF
# Apply sysctl params without reboot
sysctl --system
```

## 08 所有机器都设置文件最大数

```bash
cat>/etc/security/limits.d/kubernetes.conf<<EOF
*       soft    nproc   131072
*       hard    nproc   131072
*       soft    nofile  131072
*       hard    nofile  131072
root    soft    nproc   131072
root    hard    nproc   131072
root    soft    nofile  131072
root    hard    nofile  131072
EOF
```

## 09 新增阿里yum源，这里是Centos 7系统

```bash
curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
```

## 10 时间同步

```bash
yum install chrony -y
systemctl enable chronyd
systemctl start chronyd
chronyc sources
```

## 11 安装containerd

安装`yum-utils`包（提供`yum-config-manager` 实用程序）并设置**稳定**的存储库。

```bash
# 安装依赖软件包
yum -y install yum-utils device-mapper-persistent-data lvm2
# 添加阿里Docker源
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
# 添加overlay和netfilter模块 
cat >>/etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF
modprobe overlay
modprobe br_netfilter
# 安装Containerd，这里安装最新版本
yum -y install containerd.io
```

````bash
# 生成containerd的配置文件
mkdir /etc/containerd -p 
# 生成配置文件
containerd config default > /etc/containerd/config.toml
# 编辑配置文件 方法一 和 方法二 随便寻一个就好了
## 方法一
sed -i '/SystemdCgroup/s/false/true/g' /etc/containerd/config.toml
# 更改镜像注册地址
sed -i '/sandbox_image/s/registry.k8s.io/registry.aliyuncs.com\/google_containers/g' /etc/containerd/config.toml
````

```bash
systemctl enable containerd
systemctl start containerd
ctr images ls
ctr --v # ctr containerd.io 1.6.22
ctr version
```

## 12 安装kubectl、kubelet、kubeadm

```bash
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
# 查看所有的可用版本
yum list kubelet --showduplicates 
# 这里安装当前最新版本1.28.1
yum -y install kubectl-1.28.1 kubelet-1.28.1 kubeadm-1.28.1
# 启动kubelet
systemctl enable kubelet
systemctl start kubelet
# 查看k8s v1.28.1初始化所需要的镜像
kubeadm config images list --kubernetes-version=v1.28.1
# 初始化
kubeadm init --kubernetes-version=1.28.1 \
--apiserver-advertise-address=192.168.0.10 \
--image-repository registry.aliyuncs.com/google_containers \
--pod-network-cidr=158.16.0.0/16
```

> **注：pod的网段为: 158.16.0.0/16，api server地址为Master本机IP，网段可以自定义，不冲突即可。**
>
> **这一步很关键，由于kubeadm 默认从官网k8s.grc.io下载所需镜像，国内无法访问，因此需要通过--image-repository指定阿里云镜像仓库地址。**
>
> - --pod-network-cidr，设置集群里 Pod 的 IP 地址段

```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
export KUBECONFIG=/etc/kubernetes/admin.conf
kubectl get node
kubectl get pod -A
# 注：node节点为NotReady，因为corednspod没有启动，缺少网络pod
# kubectl命令补全功能 
yum -y install bash-completion
echo "source <(kubectl completion bash)" >> /etc/profile
source /etc/profile
```

```bash
# 安装calico网路
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
wget https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml
# 更改这个yaml文件为你自己的 --pod-network-cidr=172.16.0.0/16
...
- name: CALICO_IPV4POOL_CIDR
  value: "172.16.0.0/16"
...
kubectl apply -f custom-resources.yaml
# node-role.kubernetes.io/control-plane:NoSchedule
kubectl taint nodes --all node-role.kubernetes.io/control-plane-
kubectl taint nodes --all node-role.kubernetes.io/master-
```

```bash
kubectl get nodes -o wide
kubectl get node
kubectl get pod -n kube-system
kubectl taint nodes master01 \
        node-role.kubernetes.io/control-plane:NoSchedule
```

## 13 验证集群信息

```bash
cat <<- 'eof' |  kubectl apply -f - -n default 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.18.0
        ports:
        - containerPort: 80
eof
```

```bash
kubectl expose deployment nginx-deployment --port=81 --target-port=80  --type=NodePort --name=nginx-np-svc
kubectl expose deployment nginx-deployment --port=80 --type=LoadBalancer --name=nginx-lb-svc
```

## 14 验证集群dns

```bash
cat <<- 'eof' |  kubectl apply -f - -n default 
apiVersion: v1
kind: Pod
metadata:
  name: busybox
  namespace: default
spec:
  containers:
  - name: busybox
    image: busybox:1.28.4
    command:
      - sleep
      - "3600"
    imagePullPolicy: IfNotPresent
  restartPolicy: Always
eof
```

```bash
kubectl exec -ti busybox -- nslookup kubernetes
kubectl exec -ti busybox -- nslookup nginx-np-svc
```

#### ipvs验证

```bash
ipvsadm -ln
```

## 附注

```bash
systemctl enable kubelet 
#重置节点
kubeadm reset
systemctl restart kubelet
kubectl label node node01 node-role.kubernetes.io/edge=
find /etc -name ifcfg* -type f
```

```bash
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=none
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=ens32
UUID=5d3312cc-b729-4e59-a382-baa4a021b27a
DEVICE=ens32
ONBOOT=yes
IPADDR=192.168.0.10
PREFIX=24
GATEWAY=192.168.0.2
DNS1=114.114.114.114
IPV6_PRIVACY=no
```

#### 安装最新版本的helm

```bash
# https://github.com/helm/helm/releases
wget https://get.helm.sh/helm-v3.12.3-linux-amd64.tar.gz
#解压 Helm
tar -zxvf helm-v3.12.3-linux-amd64.tar.gz
#复制客户端执行文件到 bin 目录下，方便在系统下能执行 helm 命令
cp linux-amd64/helm /usr/local/bin/
#添加 Chart 仓库
helm repo add  elastic    https://helm.elastic.co
helm repo add  gitlab     https://charts.gitlab.io
helm repo add  harbor     https://helm.goharbor.io
helm repo add  bitnami    https://charts.bitnami.com/bitnami
helm repo add  incubator  https://kubernetes-charts-incubator.storage.googleapis.com
helm repo add  stable     https://kubernetes-charts.storage.googleapis.com
#增加完仓库后，需要执行更新命令，将仓库中的信息进行同步：
helm repo update
##Helm 的基本操作
#通过 Helm 在 Repo 中查询可安装的 nginx 包：
helm search repo nginx
#指定namespace
kubectl create namespace myki
helm install nginx bitnami/nginx -n myki
#查看应用状态
helm status nginx -n myki
#查看全部应用（包含安装和卸载的应用）
helm list --all -A
#获取配置
helm show values bitnami/nginx > values.yaml
#升级应用 创建新的配置
cat > values.yaml << EOF
service:
  nodePorts:
    http: "30077"
    https: "30078"
  type: NodePort
EOF
#应用更新
helm upgrade -f values.yaml nginx bitnami/nginx -n myki
#查看新配置是否生效 (能获取端口 原文档格式有错误)
helm get values nginx -n myki
kubectl edit svc nginx -n myki
#应用回滚
helm history nginx -n myki
helm rollback nginx 1 -n myki

#卸载应用，并保留安装记录
helm uninstall nginx -n myki --keep-history
#卸载应用，不保留安装记录
helm delete nginx -n myki
```

### 内核在线升级

```bash
rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
yum --disablerepo="*" --enablerepo="elrepo-kernel" list available
# 安装kernel-ml
yum --enablerepo=elrepo-kernel install kernel-ml kernel-ml-devel -y
```

### 设置主机名

```bash
 # hostnamectl set-hostname <主机名>
hostnamectl set-hostname master01
hostnamectl set-hostname node01
```

cilium的官方文档默认提示基础网络功能，Kernel >=4.9

```bash
http://192.168.0.10:30327/
```





